{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "AsbLJb6oFiI8"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Q3UBJ4vHX2ET",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "\n",
        "# Commonly used modules\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Images, plots, display, and visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import IPython\n",
        "from six.moves import urllib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mo7_0_FwXz1s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ta7fI4_wek3V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(43) # to make the results reproductible\n",
        "tf.set_random_seed(42) # to make the results reproductible "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HabVV_V3YT9v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 1 Importing images and setting up train test data"
      ]
    },
    {
      "metadata": {
        "id": "bbKjrVr3u_nb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.1 Importing images and creating training, validation and test datasets"
      ]
    },
    {
      "metadata": {
        "id": "WQPAiJ9VQ6Up",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Hyperparameter definition\n",
        "\n",
        "class Flags:\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.batch_size = 10\n",
        "    self.epochs = 20\n",
        "    self.image_size = 28\n",
        "    self.train_split = [0.75*0.75,0.25*0.75,0.25]\n",
        "    self.fixed_img_number = 700\n",
        "    self.loss_function = 'Adam'\n",
        "\n",
        "flags = Flags()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qjy-hUMIuOhH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = '/gdrive/My Drive/DL project_2019/Raw_Dataset'\n",
        "\n",
        "# Get the filenames and label of our data\n",
        "image_filenames = []\n",
        "image_labels = []\n",
        "species = ['Bees','Mosquitoes', 'Flies', 'Butterflies']\n",
        "for label, category in enumerate(species):\n",
        "    image_names = os.listdir(os.path.join(data_dir, category))\n",
        "    image_names = sorted(image_names) # to make the results reproductibles\n",
        "    image_names = [x for x in image_names if os.stat(os.path.join(data_dir, category, x)).st_size != 0]\n",
        "    \n",
        "    image_names = image_names[:flags.fixed_img_number]\n",
        "    image_filenames += [os.path.join(\n",
        "        data_dir, category, image_name) for image_name in image_names]\n",
        "    \n",
        "    image_labels += [label] * len(image_names)\n",
        "    \n",
        "# Split data in three for training, validation and test\n",
        "train_image_filenames, train_image_labels = [], []\n",
        "valid_image_filenames, valid_image_labels = [], []\n",
        "test_image_filenames, test_image_labels  = [], []\n",
        "\n",
        "for image_filename, image_label in zip(image_filenames, image_labels):\n",
        "\n",
        "    x = np.random.choice(['train', 'valid', 'test'], p=flags.train_split)\n",
        "\n",
        "    if x == 'train':\n",
        "        train_image_filenames.append(image_filename)\n",
        "        train_image_labels.append(image_label)\n",
        "    if x == 'valid':\n",
        "        valid_image_filenames.append(image_filename)\n",
        "        valid_image_labels.append(image_label)\n",
        "    if x == 'test':\n",
        "        test_image_filenames.append(image_filename)\n",
        "        test_image_labels.append(image_label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MQHQOGPavLWr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.2 Defining Iterators for batch training"
      ]
    },
    {
      "metadata": {
        "id": "zjL8L7qOvIbp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Iterator builder \n",
        "def make_iterator(filenames, labels, batch_size, shuffle_and_repeat=False):\n",
        "    \"\"\"function that creates a `tf.data.Iterator` object\"\"\"\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
        "    if shuffle_and_repeat:\n",
        "        dataset = dataset.apply(\n",
        "            tf.data.experimental.shuffle_and_repeat(buffer_size=1000))\n",
        "\n",
        "    def parse(filename, label):\n",
        "        \"\"\"function that reads the image and normalizes it\"\"\"\n",
        "        try:\n",
        "          image = tf.read_file(filename)\n",
        "          image = tf.image.decode_jpeg(image, channels = 3)\n",
        "          image = tf.cast(image, tf.float32)\n",
        "          image = tf.image.resize(image, (flags.image_size,flags.image_size))\n",
        "          image = image / 256\n",
        "          return {'image': image, 'label': label}\n",
        "\n",
        "    dataset = dataset.apply(tf.data.experimental.map_and_batch(\n",
        "        map_func=parse, batch_size=batch_size, num_parallel_batches=8))\n",
        "\n",
        "    if shuffle_and_repeat:\n",
        "        return dataset.make_one_shot_iterator()\n",
        "    else:\n",
        "        return dataset.make_initializable_iterator()\n",
        "\n",
        "#Building iterators\n",
        "train_iterator = make_iterator(train_image_filenames, train_image_labels,\n",
        "    batch_size=flags.batch_size, shuffle_and_repeat=True)\n",
        "val_iterator = make_iterator(valid_image_filenames, valid_image_labels,\n",
        "    batch_size=flags.batch_size, shuffle_and_repeat=True)\n",
        "test_iterator = make_iterator(test_image_filenames, test_image_labels,\n",
        "    batch_size=len(test_image_filenames), shuffle_and_repeat=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YVGivZX8k00p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 2 Constructing CNN "
      ]
    },
    {
      "metadata": {
        "id": "MoPaHYmdFa6x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.1 Model Architecture"
      ]
    },
    {
      "metadata": {
        "id": "E2MpvvCUk4XW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_builder():\n",
        "  model = keras.Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(flags.image_size, flags.image_size, 3)))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = 2, padding = 'valid'))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), strides = 2, padding = 'valid'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(len(species), activation='softmax'))\n",
        "  return model\n",
        "\n",
        "model = model_builder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ivHY2-FuXKJ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(), \n",
        "              loss= 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy']\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HRK4CQKwllSP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 3 Training model"
      ]
    },
    {
      "metadata": {
        "id": "a7mJfoRmzJFG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "\n",
        "features = train_iterator.get_next()\n",
        "images, labels = itemgetter('image', 'label')(features)\n",
        "\n",
        "val_features = val_iterator.get_next()\n",
        "val_images, val_labels = itemgetter('image', 'label')(val_features)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NFkaHa_fxrqg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(images\n",
        "                    , labels\n",
        "                    , epochs=flags.epochs\n",
        "                    , validation_data = (val_images, val_labels)\n",
        "                    , steps_per_epoch= len(train_image_labels) // flags.batch_size\n",
        "                    , validation_steps = len(valid_image_labels) // flags.batch_size\n",
        "                   )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pwvpF8qrlnbg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "features = test_iterator.get_next()\n",
        "test_images, test_labels = itemgetter('image', 'label')(features)\n",
        "\n",
        "\n",
        "print(test_images.shape)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, steps = 1)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}